# 🚀 План оптимизации Crypto Promo Bot

> **Дата создания:** 17 января 2026  
> **Статус:** Планомерная оптимизация (без спешки)  
> **Цель:** Подготовить бота к масштабированию (20-30 ссылок, 5+ browser парсеров)

---

## 📊 Текущее состояние

| Параметр | Значение |
|----------|----------|
| Парсинг | Последовательный (одна биржа за другой) |
| UI отзывчивость | Блокируется при парсинге |
| Browser парсеры | Новый браузер на каждый запрос |
| Архитектура | Монолитная (всё в одном процессе) |

---

## 🎯 Цели оптимизации

1. **Параллельный парсинг** — проверять несколько бирж одновременно
2. **Отзывчивый UI** — бот мгновенно реагирует на кнопки даже во время парсинга
3. **Экономия ресурсов** — переиспользование браузеров, оптимизация памяти
4. **Стабильность** — автовосстановление при ошибках

---

## 📚 Пояснения (что это и зачем)

### Redis — что это?
**Redis** — это быстрая база данных в памяти, которая работает как "почтовый ящик" между разными частями программы.

**Зачем нам:**
- Бот отправляет задание "проверить биржу X" в Redis
- Отдельный воркер (процесс) берёт задание и выполняет
- Бот НЕ ждёт результата — сразу обрабатывает кнопки пользователя
- Когда воркер закончил — отправляет результат обратно

**Альтернатива (без Redis):**
- `asyncio.Queue` — очередь внутри Python (проще, но менее надёжно)
- Подходит для нашего масштаба (20-30 ссылок)

**Рекомендация:** Начнём БЕЗ Redis, используя `asyncio.Queue`. Если понадобится масштабирование — добавим Redis позже.

---

### Архитектурные изменения — что будем менять?

#### Сейчас (монолит):
```
┌─────────────────────────────────────────┐
│              ОДИН ПРОЦЕСС               │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  │
│  │ Telegram│  │ Парсеры │  │Scheduler│  │
│  │   Bot   │  │         │  │         │  │
│  └─────────┘  └─────────┘  └─────────┘  │
│         ↓ БЛОКИРУЮТ ДРУГ ДРУГА ↓        │
└─────────────────────────────────────────┘
```

#### После оптимизации (разделение):
```
┌─────────────────────┐     ┌─────────────────────┐
│   ГЛАВНЫЙ ПРОЦЕСС   │     │   ВОРКЕР ПАРСИНГА   │
│  ┌─────────────┐    │     │  ┌─────────────┐    │
│  │ Telegram Bot│    │     │  │ Парсер 1    │    │
│  │ (UI, кнопки)│    │     │  │ Парсер 2    │    │
│  └─────────────┘    │     │  │ Парсер 3    │    │
│  ┌─────────────┐    │     │  └─────────────┘    │
│  │  Scheduler  │◄───┼─────┼──►  (параллельно)   │
│  └─────────────┘    │     │                     │
└─────────────────────┘     └─────────────────────┘
        │                            │
        └────── asyncio.Queue ───────┘
              (или Redis позже)
```

**Результат:**
- UI НИКОГДА не блокируется
- Парсеры работают параллельно (3-5 одновременно)
- Можно добавлять воркеры для масштабирования

---

## 🖥️ Рекомендации по серверу

### Digital Ocean (рекомендую)

| Вариант | RAM | CPU | Цена/мес | Для чего |
|---------|-----|-----|----------|----------|
| **Basic Droplet** | 2GB | 1 vCPU | $12 | Начальный этап (10-15 ссылок) |
| **Basic Droplet** | 4GB | 2 vCPU | $24 | **Рекомендую** (20-30 ссылок, 5 browser) |
| **Premium AMD** | 4GB | 2 vCPU | $32 | Если нужна скорость |

### Альтернативы

| Провайдер | Плюсы | Минусы |
|-----------|-------|--------|
| **Hetzner** | Дешевле ($4-8/мес за 4GB) | Дата-центры в Европе |
| **Vultr** | Много локаций | Чуть дороже |
| **Contabo** | Очень дёшево | Медленнее |

### 💡 Моя рекомендация
**Digital Ocean Droplet 4GB RAM / 2 vCPU** ($24/мес) — оптимально для:
- 20-30 ссылок
- 5+ browser парсеров работающих параллельно
- Playwright (требует памяти)
- Запас на рост

---

## ✅ TODO: Фаза 1 — Быстрые улучшения (1-2 дня) — ✅ ВЫПОЛНЕНО

### 1.1 Увеличить пул потоков для executor ✅
> **Проблема:** Default ThreadPoolExecutor имеет мало потоков  
> **Решение:** Создать выделенный executor с 10+ потоками

- [x] Создать глобальный `ThreadPoolExecutor(max_workers=10)` → `utils/executor.py`
- [x] Использовать его во всех `run_in_executor()` вызовах (13 мест)
- [x] Добавить настройку `EXECUTOR_MAX_WORKERS` в `config.py`
- [x] **Файлы:** `utils/executor.py`, `main.py`, `bot/handlers.py`, `config.py`

### 1.2 Добавить debounce для кнопок ✅
> **Проблема:** Быстрые нажатия создают множество запросов  
> **Решение:** Игнорировать повторные нажатия в течение 0.5 сек

- [x] Создать `DebounceMiddleware` для aiogram → `utils/debounce.py`
- [x] Автоматически применяется ко ВСЕМ callback-handlers
- [x] Добавить настройку `DEBOUNCE_SECONDS` в `config.py`
- [x] **Файлы:** `utils/debounce.py`, `main.py`, `config.py`

### 1.3 Оптимизировать логирование ✅
> **Проблема:** 50+ логов на каждую проверку биржи  
> **Решение:** Уменьшить verbosity, батчить логи

- [x] Создать централизованную настройку логирования → `utils/logging_config.py`
- [x] Уровень логирования берётся из `config.LOG_LEVEL`
- [x] Добавить запись в файл с ротацией (`logs/bot.log`, 10MB, 5 бэкапов)
- [x] Уменьшить verbosity сторонних библиотек (urllib3, httpx, etc.)
- [x] **Файлы:** `utils/logging_config.py`, `main.py`, `config.py`

---

## ✅ TODO: Фаза 2 — Пул браузеров (2-3 дня) — ✅ ВЫПОЛНЕНО

### 2.1 Создать BrowserPool ✅
> **Проблема:** Каждый запрос = новый браузер (2-5 сек startup)  
> **Решение:** Пул из 3 браузеров, переиспользуемых между запросами

- [x] Создать класс `BrowserPool` в `utils/browser_pool.py`
- [x] Методы: `acquire()`, `release()`, `shutdown()`
- [x] Лимит: 3 браузера одновременно (настраивается через `BROWSER_POOL_SIZE`)
- [x] Автоперезапуск при крашах
- [x] **Файлы:** новый `utils/browser_pool.py`, новый `parsers/async_browser_parser.py`

### 2.2 Интегрировать пул в browser_parser ✅
- [x] Создать `AsyncBrowserParser` — асинхронный парсер использующий пул
- [x] Context manager `async with pool.acquire() as browser`
- [x] Автоматическое закрытие контекста в finally
- [x] **Файлы:** `parsers/async_browser_parser.py`

### 2.3 Добавить health-check браузеров ✅
- [x] Проверять живость браузера перед использованием (`is_connected()`)
- [x] Автоматически пересоздавать "мёртвые" браузеры
- [x] Пересоздание при превышении `max_age_seconds` (30 мин)
- [x] Пересоздание при превышении `max_requests` (50 запросов)
- [x] Фоновый health-check каждые 60 секунд
- [x] **Файлы:** `utils/browser_pool.py`

### 2.4 Конфигурация ✅
- [x] `BROWSER_POOL_SIZE` — размер пула (по умолчанию 3)
- [x] `BROWSER_MAX_AGE_SECONDS` — максимальный возраст браузера (30 мин)
- [x] `BROWSER_MAX_REQUESTS` — максимум запросов на браузер (50)
- [x] `BROWSER_HEALTH_CHECK_INTERVAL` — интервал проверки (60 сек)
- [x] `BROWSER_POOL_ENABLED` — включение/отключение пула
- [x] **Файлы:** `config.py`, `main.py`

---

## ✅ TODO: Фаза 3 — Параллельный парсинг (3-5 дней) — ✅ ВЫПОЛНЕНО

### 3.1 Создать очередь задач ✅
> **Проблема:** Парсинг бирж идёт последовательно  
> **Решение:** asyncio.Queue + worker pool

- [x] Создать класс `ParsingQueue` в `utils/parsing_queue.py`
- [x] Методы: `add_task()`, `get_results()`, `shutdown()`
- [x] Класс `ParsingTask` с приоритетами и статусами
- [x] **Файлы:** новый `utils/parsing_queue.py`

### 3.2 Создать воркеры парсинга ✅
- [x] Создать класс `ParsingWorker` — берёт задачи из очереди
- [x] Создать класс `ParsingWorkerPool` — управляет воркерами
- [x] Запускать 5 воркеров параллельно (настраивается)
- [x] Каждый воркер берёт задачу из очереди и выполняет парсинг
- [x] Callback для отправки уведомлений по мере готовности
- [x] **Файлы:** новый `services/parsing_worker.py`

### 3.3 Переписать smart_auto_check ✅
- [x] Добавлен метод `_smart_auto_check_parallel()` — использует Worker Pool
- [x] Добавлен метод `_smart_auto_check_sequential()` — fallback
- [x] Автовыбор: параллельный если включен, иначе последовательный
- [x] Добавлен callback `_handle_parsing_result()` для уведомлений
- [x] **Файлы:** `main.py`

### 3.4 Добавить приоритеты задач ✅
- [x] `TaskPriority.CRITICAL` — критические проверки
- [x] `TaskPriority.HIGH` — ручная проверка пользователем
- [x] `TaskPriority.NORMAL` — автоматическая проверка
- [x] `TaskPriority.LOW` — фоновые задачи
- [x] **Файлы:** `utils/parsing_queue.py`

### 3.5 Конфигурация ✅
- [x] `PARALLEL_PARSING_ENABLED` — включение параллельного парсинга
- [x] `PARALLEL_PARSING_WORKERS` — количество воркеров (по умолчанию 5)
- [x] `PARALLEL_PARSING_QUEUE_SIZE` — размер очереди (по умолчанию 100)
- [x] `PARALLEL_PARSING_TASK_TIMEOUT` — таймаут задачи (120 сек)
- [x] `PARALLEL_PARSING_MAX_RETRIES` — макс. повторов (3)
- [x] **Файлы:** `config.py`

---

## ✅ TODO: Фаза 4 — Отзывчивый UI (2-3 дня) — ✅ ВЫПОЛНЕНО

### 4.1 Вынести тяжёлые операции из callback handlers ✅
> **Проблема:** Handlers делают синхронные запросы к БД  
> **Решение:** Использовать async операции

- [x] Создать `async def get_links_async()` и аналогичные → `data/database.py`
- [x] Создать `get_link_by_id_async()`, `update_link_async()`, `delete_link_async()`
- [x] Создать `create_link_async()` для создания новых ссылок
- [x] Добавить `run_in_db_executor()` для выполнения sync кода в async контексте
- [x] Интегрировать async функции в `bot/handlers.py`
- [x] **Файлы:** `data/database.py`, `bot/handlers.py`

### 4.2 Добавить loading индикаторы ✅
- [x] Создать `LoadingContext` — контекстный менеджер для loading состояний
- [x] Создать декоратор `@with_loading()` для автоматического отображения загрузки
- [x] Создать `LoadingAnimation` для анимированных индикаторов
- [x] Добавить `LoadingTexts` — предопределённые тексты загрузки
- [x] Интегрировать в `view_current_stakings()` и `view_current_promos()`
- [x] **Файлы:** новый `utils/loading_indicator.py`, `bot/handlers.py`

### 4.3 Кэширование частых запросов ✅
- [x] Создать класс `CacheManager` с TTL и LRU логикой
- [x] Добавить декораторы `@async_cache()` и `@sync_cache()`
- [x] Кэшировать список ссылок на 30 сек (автоматически через async функции)
- [x] Добавить `CacheKeys` — константы ключей кэша
- [x] Добавить `invalidate_links_cache()`, `invalidate_promos_cache()`, `invalidate_stakings_cache()`
- [x] **Файлы:** новый `utils/cache.py`

### 4.4 Конфигурация ✅
- [x] `CACHE_ENABLED` — включение кэширования
- [x] `CACHE_MAX_SIZE` — максимум записей (1000)
- [x] `CACHE_DEFAULT_TTL` — TTL по умолчанию (30 сек)
- [x] `CACHE_LINKS_TTL` — TTL для ссылок (30 сек)
- [x] `CACHE_PROMOS_TTL` — TTL для промо (60 сек)
- [x] `CACHE_STAKINGS_TTL` — TTL для стейкингов (60 сек)
- [x] **Файлы:** `config.py`

---

## ✅ TODO: Фаза 5 — Стабильность (2-3 дня) — ✅ ВЫПОЛНЕНО

### 5.1 Circuit Breaker для бирж ✅
> **Проблема:** Если биржа лежит — тратим время на таймауты  
> **Решение:** После 3 неудач — пропускать биржу на 5 минут

- [x] Создать `CircuitBreaker` в `utils/circuit_breaker.py`
- [x] Три состояния: CLOSED (норма), OPEN (блокировка), HALF_OPEN (проба)
- [x] Автоматический переход между состояниями
- [x] Декоратор `@with_circuit_breaker()` для автоматической интеграции
- [x] Интегрировать в `services/parsing_worker.py`
- [x] **Файлы:** новый `utils/circuit_breaker.py`, `services/parsing_worker.py`

### 5.2 Graceful degradation ✅
- [x] При нехватке памяти — автоматически уменьшать число параллельных парсеров
- [x] WARNING (70%): уменьшение воркеров до половины
- [x] CRITICAL (85%): уменьшение до 1 воркера
- [x] NORMAL: автоматическое восстановление до начального количества
- [x] **Файлы:** `services/parsing_worker.py`

### 5.3 Мониторинг ресурсов ✅
- [x] Создать `ResourceMonitor` в `utils/resource_monitor.py`
- [x] Мониторинг RAM/CPU использования (системного и процесса)
- [x] Логирование статистики каждые N минут (настраивается)
- [x] Callbacks для WARNING и CRITICAL состояний
- [x] Алерт в Telegram при критическом состоянии (RAM > 85%)
- [x] Метод `get_recommended_workers()` для Graceful degradation
- [x] **Файлы:** новый `utils/resource_monitor.py`, `main.py`

### 5.4 Автовосстановление ✅
- [x] При краше воркера — автоматический перезапуск после паузы
- [x] Счётчик последовательных ошибок с паузой после 5 ошибок
- [x] Статистика перезапусков в воркерах
- [x] Логирование критических ошибок с номером рестарта
- [x] **Файлы:** `services/parsing_worker.py`

### 5.5 Конфигурация ✅
- [x] `CIRCUIT_BREAKER_ENABLED` — включение Circuit Breaker
- [x] `CIRCUIT_BREAKER_FAILURE_THRESHOLD` — неудач для блокировки (3)
- [x] `CIRCUIT_BREAKER_RECOVERY_TIMEOUT` — время блокировки (300с = 5 мин)
- [x] `CIRCUIT_BREAKER_SUCCESS_THRESHOLD` — успехов для разблокировки (2)
- [x] `RESOURCE_MONITOR_ENABLED` — включение мониторинга
- [x] `RESOURCE_MONITOR_INTERVAL` — интервал проверки (300с = 5 мин)
- [x] `RESOURCE_RAM_WARNING_PERCENT` — порог предупреждения RAM (70%)
- [x] `RESOURCE_RAM_CRITICAL_PERCENT` — критический порог RAM (85%)
- [x] `GRACEFUL_DEGRADATION_ENABLED` — включение адаптивного снижения
- [x] `GRACEFUL_DEGRADATION_CHECK_INTERVAL` — интервал проверки (60с)
- [x] **Файлы:** `config.py`

---

## TODO: Фаза 6 — Подготовка к продакшену (1-2 дня)

### 6.1 Конфигурация для разных окружений
- [ ] `config.py` — development/production режимы
- [ ] Разные уровни логирования
- [ ] **Файлы:** `config.py`

### 6.2 Healthcheck endpoint
- [ ] Простой HTTP endpoint для мониторинга
- [ ] Показывает статус бота, очереди, воркеров
- [ ] **Файлы:** новый `utils/healthcheck.py`

### 6.3 Документация деплоя
- [ ] Обновить `deploy/README.md`
- [ ] Docker-compose файл (опционально)
- [ ] **Файлы:** `deploy/`

---

## 📅 Примерный план по неделям

| Неделя | Фаза | Результат |
|--------|------|-----------|
| 1 | Фаза 1 + 2 | UI быстрее, браузеры переиспользуются |
| 2 | Фаза 3 | Параллельный парсинг работает |
| 3 | Фаза 4 + 5 | Полностью отзывчивый UI, стабильность |
| 4 | Фаза 6 | Готов к деплою на сервер |

---

## 🔧 Технический стек после оптимизации

```
┌─────────────────────────────────────────────────────┐
│                    CRYPTO PROMO BOT                  │
├─────────────────────────────────────────────────────┤
│                                                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  │
│  │  Telegram   │  │   Parsing   │  │  Browser    │  │
│  │    Bot      │  │   Queue     │  │   Pool      │  │
│  │  (aiogram)  │  │(asyncio.Q)  │  │ (Playwright)│  │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘  │
│         │                │                │         │
│         ▼                ▼                ▼         │
│  ┌─────────────────────────────────────────────┐   │
│  │              WORKERS (3-5 параллельных)      │   │
│  │  ┌────────┐  ┌────────┐  ┌────────┐         │   │
│  │  │Worker 1│  │Worker 2│  │Worker 3│  ...    │   │
│  │  └────────┘  └────────┘  └────────┘         │   │
│  └─────────────────────────────────────────────┘   │
│                        │                            │
│                        ▼                            │
│  ┌─────────────────────────────────────────────┐   │
│  │                 SQLite + Cache               │   │
│  └─────────────────────────────────────────────┘   │
│                                                     │
└─────────────────────────────────────────────────────┘
```

---

## 📝 Заметки

- **Redis НЕ нужен** для 20-30 ссылок — `asyncio.Queue` достаточно
- **Docker опционален** — можно деплоить напрямую на VPS
- **Начинаем с простого** — постепенно усложняем по мере необходимости

---

## ❓ Вопросы для обсуждения

1. Хотите начать с Фазы 1 (быстрые улучшения)?
2. Какая биржа сейчас самая проблемная (долго парсится)?
3. Нужен ли Docker или деплоим напрямую?

---

*Обновлено: 17.01.2026*
