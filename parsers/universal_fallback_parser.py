# parsers/universal_fallback_parser.py
"""
–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô FALLBACK –ü–ê–†–°–ï–† –î–õ–Ø CRYPTO PROMO BOT v3.0
–ú—É–ª—å—Ç–∏-—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥: API ‚Üí HTML ‚Üí –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
"""

import logging
import hashlib
import time
import requests
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup

from .base_parser import BaseParser
from .html_templates import get_html_selectors, get_html_urls

logger = logging.getLogger(__name__)

class UniversalFallbackParser(BaseParser):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback –º–µ–∂–¥—É API –∏ HTML"""

    def __init__(self, url: str, api_urls: List[str] = None, html_urls: List[str] = None):
        super().__init__(url)
        self.strategy_used = None
        self.combined_data = []
        self.exchange = self._extract_exchange_from_url(url)  # ‚úÖ –î–û–ë–ê–í–ò–¢–¨
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ URL –¥–ª—è FALLBACK —Å–∏—Å—Ç–µ–º—ã
        self.api_urls = api_urls or []
        self.html_urls = html_urls or []
        
    def _extract_exchange_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏ –∏–∑ URL"""
        if 'bybit' in url.lower():
            return 'bybit'
        elif 'binance' in url.lower():
            return 'binance'
        elif 'mexc' in url.lower():
            return 'mexc'
        elif 'gate' in url.lower():
            return 'gate'
        elif 'okx' in url.lower():
            return 'okx'
        elif 'bitget' in url.lower():
            return 'bitget'
        else:
            return 'unknown'
    
    def _make_request(self, url: str) -> Optional[requests.Response]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É —Ä–æ—Ç–∞—Ü–∏–∏"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ make_request –∏–∑ BaseParser
            response = self.make_request(url)
            return response
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {url}: {e}")
            return None
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def get_promotions(self) -> List[Dict[str, Any]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π"""
        logger.info("=" * 80)
        logger.info(f"üéØ UniversalFallbackParser: –ù–∞—á–∞–ª–æ –º—É–ª—å—Ç–∏-—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        logger.info(f"   –ë–∏—Ä–∂–∞: {self.exchange}")
        logger.info(f"   URL: {self.url}")

        strategy_priority = self._get_strategy_priority()
        logger.info(f"üìã –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è {self.exchange}: {strategy_priority}")

        results = []

        for i, strategy in enumerate(strategy_priority, 1):
            try:
                logger.info("-" * 60)
                logger.info(f"üîÑ –°—Ç—Ä–∞—Ç–µ–≥–∏—è {i}/{len(strategy_priority)}: {strategy.upper()}")

                if strategy == "api" and self._is_api_url():
                    logger.info(f"üîß –ù–∞—á–∞–ª–æ API –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    logger.info(f"   URL —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∫–∞–∫ API endpoint: {self.url}")

                    api_results = self._parse_via_api()

                    if api_results:
                        results.extend(api_results)
                        self.strategy_used = "api"
                        logger.info(f"‚úÖ API –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(api_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(api_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(api_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(api_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è API –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                elif strategy == "html":
                    logger.info(f"üåê –ù–∞—á–∞–ª–æ HTML –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    html_results = self._parse_via_html()

                    if html_results:
                        results.extend(html_results)
                        self.strategy_used = "html" if not self.strategy_used else "combined"
                        logger.info(f"‚úÖ HTML –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(html_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(html_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(html_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(html_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è HTML –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                else:
                    if strategy == "api" and not self._is_api_url():
                        logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º API –ø–∞—Ä—Å–∏–Ω–≥: URL –Ω–µ —è–≤–ª—è–µ—Ç—Å—è API endpoint")

            except Exception as e:
                logger.error(f"‚ùå –û–®–ò–ë–ö–ê –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy} –¥–ª—è {self.exchange}: {e}", exc_info=True)
                continue

        logger.info("-" * 60)

        if len(results) > 0:
            logger.info(f"üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            final_results = self._combine_and_deduplicate(results)
            logger.info(f"üéâ –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {len(final_results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
            logger.info(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {self.strategy_used}")
            logger.info("=" * 80)
            return final_results
        else:
            logger.error(f"‚ùå –í–°–ï –°–¢–†–ê–¢–ï–ì–ò–ò –ü–ê–†–°–ò–ù–ì–ê –ü–†–û–í–ê–õ–ò–õ–ò–°–¨ –¥–ª—è {self.exchange}")
            logger.error(f"   –ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {strategy_priority}")
            logger.info("=" * 80)
            return []
    
    def _get_strategy_priority(self) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –±–∏—Ä–∂–∏"""
        strategy_map = {
            "bybit": ["html", "api"],
            "mexc": ["api", "html"],
            "binance": ["html"],
            "gate": ["html"],
            "okx": ["html"],
            "bitget": ["html"]
        }
        return strategy_map.get(self.exchange, ["html", "api"])
    
    def _is_api_url(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL API endpoint'–æ–º"""
        api_indicators = ['/api/', '/x-api/', '/v1/', '/v2/', '/v3/', '/v4/', '/v5/']
        return any(indicator in self.url.lower() for indicator in api_indicators)
    
    def _parse_via_api(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ API (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç UniversalParser) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö URL"""
        try:
            from .universal_parser import UniversalParser

            all_api_promos = []

            # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π URL –µ—Å–ª–∏ –æ–Ω API
            if self._is_api_url():
                logger.info(f"üì° –ü–∞—Ä—Å–∏–Ω–≥ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ API URL: {self.url}")
                api_parser = UniversalParser(self.url)
                promotions = api_parser.get_promotions()

                for promo in promotions:
                    promo['data_source'] = 'api'
                    promo['source_url'] = self.url
                    if not promo.get('promo_id'):
                        promo['promo_id'] = self._generate_html_promo_id(promo)

                all_api_promos.extend(promotions)
                logger.info(f"‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π API URL –≤–µ—Ä–Ω—É–ª {len(promotions)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")

            # –ü–∞—Ä—Å–∏–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ API URLs
            if self.api_urls:
                logger.info(f"üì° –ü–∞—Ä—Å–∏–Ω–≥ {len(self.api_urls)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö API URLs...")
                for i, api_url in enumerate(self.api_urls, 1):
                    try:
                        logger.info(f"   [{i}/{len(self.api_urls)}] –ü–∞—Ä—Å–∏–Ω–≥ {api_url}")
                        api_parser = UniversalParser(api_url)
                        promotions = api_parser.get_promotions()

                        for promo in promotions:
                            promo['data_source'] = 'api'
                            promo['source_url'] = api_url
                            if not promo.get('promo_id'):
                                promo['promo_id'] = self._generate_html_promo_id(promo)

                        all_api_promos.extend(promotions)
                        logger.info(f"   ‚úÖ API URL #{i} –≤–µ—Ä–Ω—É–ª {len(promotions)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")

                    except Exception as e:
                        logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ API URL #{i}: {e}")
                        continue

            logger.info(f"üìä –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(all_api_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –∏–∑ –≤—Å–µ—Ö API URLs")
            return all_api_promos

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ API –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []
    
    def _parse_via_html(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö URL"""
        try:
            all_html_urls = []

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π URL –µ—Å–ª–∏ –æ–Ω –Ω–µ API
            if not self._is_api_url():
                all_html_urls.append(self.url)
                logger.info(f"üåê –î–æ–±–∞–≤–ª–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π HTML URL: {self.url}")

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ HTML URLs –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            if self.html_urls:
                all_html_urls.extend(self.html_urls)
                logger.info(f"üåê –î–æ–±–∞–≤–ª–µ–Ω–æ {len(self.html_urls)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö HTML URLs –∏–∑ –ë–î")

            # –ï—Å–ª–∏ –Ω–µ—Ç URL –∏–∑ –ë–î, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —à–∞–±–ª–æ–Ω–æ–≤
            if not all_html_urls:
                logger.info(f"üîç –ü–æ–∏—Å–∫ HTML URL –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange} –≤ —à–∞–±–ª–æ–Ω–∞—Ö...")
                html_urls = get_html_urls(self.exchange)

                if not html_urls:
                    logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö HTML URL –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange}")
                    logger.warning(f"   –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å HTML —Å—Å—ã–ª–∫–∏ —á–µ—Ä–µ–∑ –±–æ—Ç –∏–ª–∏ –≤ html_templates.py")
                    return []

                all_html_urls.extend(html_urls)

            logger.info(f"üìã –í—Å–µ–≥–æ {len(all_html_urls)} HTML URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞:")
            for i, url in enumerate(all_html_urls, 1):
                logger.info(f"   {i}. {url}")

            all_html_promos = []

            for i, html_url in enumerate(all_html_urls, 1):
                try:
                    logger.info(f"üåê [{i}/{len(all_html_urls)}] –ü–∞—Ä—Å–∏–Ω–≥ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {html_url}")
                    response = self._make_request(html_url)

                    if not response:
                        logger.warning(f"‚ö†Ô∏è –ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç {html_url}")
                        continue

                    if response.status_code != 200:
                        logger.warning(f"‚ö†Ô∏è –ù–µ—É—Å–ø–µ—à–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∫–æ–¥ {response.status_code} –¥–ª—è {html_url}")
                        continue

                    logger.info(f"‚úÖ HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")

                    html_promos = self._parse_html_content(response.text, html_url)
                    all_html_promos.extend(html_promos)

                    if html_promos:
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(html_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –≤ {html_url}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {html_url}")

                    if i < len(all_html_urls):
                        logger.debug(f"‚è≥ –ü–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º...")
                        time.sleep(2)

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML {html_url}: {e}", exc_info=True)
                    continue

            logger.info(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(all_html_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –∏–∑ –≤—Å–µ—Ö HTML URLs")
            return all_html_promos

        except Exception as e:
            logger.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return []
    
    def _parse_html_content(self, html_content: str, source_url: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            selectors = get_html_selectors(self.exchange)
            
            if not selectors:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange}")
                return []
            
            containers = soup.select(selectors['container'])
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–∞ {self.exchange}")
            
            promotions = []
            
            for container in containers:
                try:
                    promo = self._extract_promo_from_container(container, selectors, source_url)
                    if promo and self._is_valid_promo(promo):
                        promotions.append(promo)
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–º–æ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
                    continue
            
            return promotions
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return []
    
    def _extract_promo_from_container(self, container, selectors: dict, source_url: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –∏–∑ HTML –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        try:
            promo = {
                'exchange': self.exchange,
                'data_source': 'html',
                'source_url': source_url
            }
            
            title_element = container.select_one(selectors['title'])
            if title_element:
                promo['title'] = title_element.get_text(strip=True)
            
            desc_element = container.select_one(selectors.get('description', ''))
            if desc_element:
                promo['description'] = desc_element.get_text(strip=True)
            
            link_element = container.select_one(selectors.get('link', ''))
            if link_element and link_element.get('href'):
                link = link_element.get('href')
                if link.startswith('/'):
                    base_domain = '/'.join(source_url.split('/')[:3])
                    promo['link'] = base_domain + link
                else:
                    promo['link'] = link
            
            time_element = container.select_one(selectors.get('time', ''))
            if time_element:
                promo['start_time'] = time_element.get_text(strip=True)
            
            prize_element = container.select_one(selectors.get('prize', ''))
            if prize_element:
                promo['total_prize_pool'] = prize_element.get_text(strip=True)
            
            token_element = container.select_one(selectors.get('token', ''))
            if token_element:
                promo['award_token'] = token_element.get_text(strip=True)
            
            participants_element = container.select_one(selectors.get('participants', ''))
            if participants_element:
                promo['participants_count'] = participants_element.get_text(strip=True)
            
            image_element = container.select_one(selectors.get('image', ''))
            if image_element and image_element.get('src'):
                promo['icon'] = image_element.get('src')
            
            if promo.get('title') or promo.get('link'):
                promo['promo_id'] = self._generate_html_promo_id(promo)
                return promo
            
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–º–æ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
            return None
    
    def _generate_html_promo_id(self, promo: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è HTML –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏"""
        try:
            title = promo.get('title', '')
            link = promo.get('link', '')
            exchange = promo.get('exchange', '')
            
            stable_key = f"{exchange}_{title}_{link}"
            content_hash = hashlib.md5(stable_key.encode('utf-8')).hexdigest()[:12]
            return f"{exchange}_html_{content_hash}"
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HTML ID: {e}")
            return f"{self.exchange}_html_error"
    
    def _is_valid_promo(self, promo: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏"""
        if not promo.get('title') and not promo.get('description'):
            return False
        
        if not promo.get('promo_id'):
            return False
        
        return True
    
    def _combine_and_deduplicate(self, promotions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            unique_promos = {}
            
            for promo in promotions:
                promo_id = promo.get('promo_id')
                if not promo_id:
                    continue
                
                if promo_id in unique_promos:
                    existing_promo = unique_promos[promo_id]
                    self._merge_promo_data(existing_promo, promo)
                else:
                    unique_promos[promo_id] = promo
            
            return list(unique_promos.values())
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return promotions
    
    def _merge_promo_data(self, existing_promo: Dict[str, Any], new_promo: Dict[str, Any]):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            for key, value in new_promo.items():
                if key not in existing_promo or not existing_promo[key]:
                    existing_promo[key] = value
            
            if 'data_sources' not in existing_promo:
                existing_promo['data_sources'] = []
            
            source = new_promo.get('data_source', 'unknown')
            if source not in existing_promo['data_sources']:
                existing_promo['data_sources'].append(source)
            
            if len(existing_promo['data_sources']) > 1:
                existing_promo['data_source'] = 'combined'
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def get_strategy_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        return {
            'exchange': self.exchange,
            'strategy_used': self.strategy_used,
            'url': self.url,
            'combined_data_count': len(self.combined_data)
        }

    def get_error_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        # –ü–æ–∫–∞ —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ –æ—à–∏–±–æ–∫
        return {
            'total_errors': 0,
            'api_errors': 0,
            'html_errors': 0
        }


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
if __name__ == "__main__":
    def test_fallback_parser():
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ fallback –ø–∞—Ä—Å–µ—Ä–∞"""
        test_urls = [
            "https://www.mexc.com/api/financialactivity/launchpad/list",  # API
            "https://www.bybit.com/en/trade/spot/token-splash",  # HTML
            "https://www.binance.com/ru/"  # HTML
        ]
        
        for url in test_urls:
            print(f"\n=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {url} ===")
            try:
                parser = UniversalFallbackParser(url)
                promos = parser.get_promotions()
                print(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π: {len(promos)}")
                if promos:
                    for promo in promos[:2]:
                        print(f" - {promo.get('title')} | {promo.get('link')}")
                print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è: {parser.get_strategy_info()}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    test_fallback_parser()