# parsers/universal_fallback_parser.py
"""
–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô FALLBACK –ü–ê–†–°–ï–† –î–õ–Ø CRYPTO PROMO BOT v3.0
–ú—É–ª—å—Ç–∏-—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥: API ‚Üí HTML ‚Üí –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
"""

import logging
import hashlib
import time
import requests
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup

from .base_parser import BaseParser
from .html_templates import get_html_selectors, get_html_urls

logger = logging.getLogger(__name__)

class UniversalFallbackParser(BaseParser):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback –º–µ–∂–¥—É API –∏ HTML"""

    def __init__(self, url: str, api_url: str = None, html_url: str = None, api_urls: List[str] = None, html_urls: List[str] = None, parsing_type: str = 'combined'):
        super().__init__(url)
        self.strategy_used = None
        self.combined_data = []
        self.exchange = self._extract_exchange_from_url(url)
        self.parsing_type = parsing_type  # –ù–û–í–û–ï: —Ç–∏–ø –ø–∞—Ä—Å–∏–Ω–≥–∞ (api, html, browser, combined)

        # –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê: –æ–¥–∏–Ω–æ—á–Ω—ã–µ URL
        self.api_url = api_url
        self.html_url = html_url

        # LEGACY: –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–æ–π (—Å–ø–∏—Å–∫–∏)
        if api_urls:
            logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Å–∏—Å—Ç–µ–º–∞ api_urls (—Å–ø–∏—Å–æ–∫). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ api_url (–æ–¥–∏–Ω–æ—á–Ω—ã–π).")
            self.api_url = api_urls[0] if api_urls else None
        if html_urls:
            logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Å–∏—Å—Ç–µ–º–∞ html_urls (—Å–ø–∏—Å–æ–∫). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ html_url (–æ–¥–∏–Ω–æ—á–Ω—ã–π).")
            self.html_url = html_urls[0] if html_urls else None
        
    def _extract_exchange_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏ –∏–∑ URL"""
        if 'bybit' in url.lower():
            return 'bybit'
        elif 'binance' in url.lower():
            return 'binance'
        elif 'mexc' in url.lower():
            return 'mexc'
        elif 'gate' in url.lower():
            return 'gate'
        elif 'okx' in url.lower():
            return 'okx'
        elif 'bitget' in url.lower():
            return 'bitget'
        else:
            return 'unknown'
    
    def _make_request(self, url: str) -> Optional[requests.Response]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É —Ä–æ—Ç–∞—Ü–∏–∏"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ make_request –∏–∑ BaseParser
            response = self.make_request(url)
            return response
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {url}: {e}")
            return None
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def get_promotions(self) -> List[Dict[str, Any]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π"""
        logger.info("=" * 80)
        logger.info(f"üéØ UniversalFallbackParser: –ù–∞—á–∞–ª–æ –º—É–ª—å—Ç–∏-—Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        logger.info(f"   –ë–∏—Ä–∂–∞: {self.exchange}")
        logger.info(f"   URL: {self.url}")

        strategy_priority = self._get_strategy_priority()
        logger.info(f"üìã –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è {self.exchange}: {strategy_priority}")

        results = []

        for i, strategy in enumerate(strategy_priority, 1):
            try:
                logger.info("-" * 60)
                logger.info(f"üîÑ –°—Ç—Ä–∞—Ç–µ–≥–∏—è {i}/{len(strategy_priority)}: {strategy.upper()}")

                if strategy == "api" and (self._is_api_url() or self.api_url):
                    logger.info(f"üîß –ù–∞—á–∞–ª–æ API –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    if self.api_url:
                        logger.info(f"   API URL –∑–∞–¥–∞–Ω: {self.api_url}")
                    if self._is_api_url():
                        logger.info(f"   –ì–ª–∞–≤–Ω—ã–π URL —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∫–∞–∫ API endpoint: {self.url}")

                    api_results = self._parse_via_api()

                    if api_results:
                        results.extend(api_results)
                        self.strategy_used = "api"
                        logger.info(f"‚úÖ API –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(api_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(api_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(api_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(api_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è API –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                elif strategy == "html":
                    logger.info(f"üåê –ù–∞—á–∞–ª–æ HTML –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    html_results = self._parse_via_html()

                    if html_results:
                        results.extend(html_results)
                        self.strategy_used = "html" if not self.strategy_used else "combined"
                        logger.info(f"‚úÖ HTML –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(html_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(html_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(html_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(html_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è HTML –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                elif strategy == "browser":
                    logger.info(f"üåê –ù–∞—á–∞–ª–æ Browser –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    browser_results = self._parse_via_browser()

                    if browser_results:
                        results.extend(browser_results)
                        self.strategy_used = "browser" if not self.strategy_used else "combined"
                        logger.info(f"‚úÖ Browser –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(browser_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(browser_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(browser_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(browser_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è Browser –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                elif strategy == "telegram":
                    logger.info(f"üì± –ù–∞—á–∞–ª–æ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {self.exchange}")
                    telegram_results = self._parse_via_telegram()

                    if telegram_results:
                        results.extend(telegram_results)
                        self.strategy_used = "telegram" if not self.strategy_used else "combined"
                        logger.info(f"‚úÖ Telegram –ø–∞—Ä—Å–∏–Ω–≥ –£–°–ü–ï–®–ï–ù: –Ω–∞–π–¥–µ–Ω–æ {len(telegram_results)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                        for j, promo in enumerate(telegram_results[:5], 1):
                            logger.info(f"   {j}. {promo.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                        if len(telegram_results) > 5:
                            logger.info(f"   ... –∏ –µ—â–µ {len(telegram_results) - 5} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
                    else:
                        logger.warning(f"‚ö†Ô∏è Telegram –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                else:
                    if strategy == "api" and not self._is_api_url() and not self.api_url:
                        logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º API –ø–∞—Ä—Å–∏–Ω–≥: –Ω–µ—Ç API URL")

            except Exception as e:
                logger.error(f"‚ùå –û–®–ò–ë–ö–ê –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy} –¥–ª—è {self.exchange}: {e}", exc_info=True)
                continue

        logger.info("-" * 60)

        if len(results) > 0:
            logger.info(f"üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            final_results = self._combine_and_deduplicate(results)
            logger.info(f"üéâ –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {len(final_results)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
            logger.info(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {self.strategy_used}")
            logger.info("=" * 80)
            return final_results
        else:
            logger.error(f"‚ùå –í–°–ï –°–¢–†–ê–¢–ï–ì–ò–ò –ü–ê–†–°–ò–ù–ì–ê –ü–†–û–í–ê–õ–ò–õ–ò–°–¨ –¥–ª—è {self.exchange}")
            logger.error(f"   –ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {strategy_priority}")
            logger.info("=" * 80)
            return []
    
    def _get_strategy_priority(self) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –±–∏—Ä–∂–∏

        –í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –ø–∞—Ä—Å–∏–Ω–≥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–Ω.
        –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∏—Ä–∂–∏.
        """
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –ø–∞—Ä—Å–∏–Ω–≥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ
        if self.parsing_type and self.parsing_type != 'combined':
            logger.info(f"üéØ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ç–∏–ø –ø–∞—Ä—Å–∏–Ω–≥–∞: {self.parsing_type}")
            return [self.parsing_type]

        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∏—Ä–∂–∏
        strategy_map = {
            # –°–∞–π—Ç—ã —Å Akamai –∑–∞—â–∏—Ç–æ–π - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç browser –ø–∞—Ä—Å–µ—Ä—É
            "bybit": ["browser", "html", "api"],  # Akamai –∑–∞—â–∏—Ç–∞, browser –ø–µ—Ä–≤—ã–π
            "mexc": ["browser", "api", "html"],   # Akamai –∑–∞—â–∏—Ç–∞, browser –ø–µ—Ä–≤—ã–π
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∞–π—Ç—ã - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            "binance": ["html", "browser"],
            "gate": ["html", "browser"],
            "okx": ["html", "browser"],
            "bitget": ["html", "browser"]
        }
        return strategy_map.get(self.exchange, ["html", "api", "browser"])
    
    def _is_api_url(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL API endpoint'–æ–º"""
        api_indicators = ['/api/', '/x-api/', '/v1/', '/v2/', '/v3/', '/v4/', '/v5/']
        return any(indicator in self.url.lower() for indicator in api_indicators)
    
    def _parse_via_api(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ API (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç UniversalParser) —Å –æ–¥–∏–Ω–æ—á–Ω—ã–º URL"""
        try:
            from .universal_parser import UniversalParser

            all_api_promos = []

            # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π URL –µ—Å–ª–∏ –æ–Ω API
            if self._is_api_url():
                logger.info(f"üëæ –ü–∞—Ä—Å–∏–Ω–≥ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ API URL: {self.url}")
                api_parser = UniversalParser(self.url)
                promotions = api_parser.get_promotions()

                for promo in promotions:
                    promo['data_source'] = 'api'
                    promo['source_url'] = self.url
                    if not promo.get('promo_id'):
                        promo['promo_id'] = self._generate_html_promo_id(promo)

                all_api_promos.extend(promotions)
                logger.info(f"‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π API URL –≤–µ—Ä–Ω—É–ª {len(promotions)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")

            # –ü–∞—Ä—Å–∏–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π API URL (–ù–û–í–û–ï: –æ–¥–∏–Ω–æ—á–Ω—ã–π)
            if self.api_url and self.api_url != self.url:
                logger.info(f"üëæ –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ API URL: {self.api_url}")
                try:
                    api_parser = UniversalParser(self.api_url)
                    promotions = api_parser.get_promotions()

                    for promo in promotions:
                        promo['data_source'] = 'api'
                        promo['source_url'] = self.api_url
                        if not promo.get('promo_id'):
                            promo['promo_id'] = self._generate_html_promo_id(promo)

                    all_api_promos.extend(promotions)
                    logger.info(f"‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π API URL –≤–µ—Ä–Ω—É–ª {len(promotions)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ API URL: {e}")

            logger.info(f"üìä –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(all_api_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –∏–∑ –≤—Å–µ—Ö API URLs")
            return all_api_promos

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ API –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []
    
    def _parse_via_browser(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä (Playwright) –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å–∞–π—Ç–æ–≤"""
        try:
            from .browser_parser import BrowserParser

            # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π URL —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä
            logger.info(f"üåê –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä: {self.url}")
            browser_parser = BrowserParser(self.url)
            promotions = browser_parser.get_promotions()

            for promo in promotions:
                promo['data_source'] = 'browser'
                promo['source_url'] = self.url

            logger.info(f"üìä Browser –ø–∞—Ä—Å–µ—Ä –≤–µ—Ä–Ω—É–ª {len(promotions)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π")
            return promotions

        except ImportError as e:
            logger.error(f"‚ùå Playwright –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
            logger.error(f"   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install playwright && python -m playwright install chromium")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Browser –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return []

    def _parse_via_telegram(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Telegram –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞

        –í–ê–ñ–ù–û: –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ TelegramMonitor!
        """
        try:
            import asyncio
            from parsers.telegram_parser import TelegramParser
            from data.database import get_db_session
            from data.models import ApiLink

            logger.info("üì± –ó–∞–ø—É—Å–∫ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞...")

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ –∏–∑ –ë–î
            telegram_channel = None
            keywords = []

            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–∞–Ω–∞–ª –∏–∑ URL
            if '@' in self.url:
                # –§–æ—Ä–º–∞—Ç: @channelname –∏–ª–∏ https://t.me/channelname
                if self.url.startswith('@'):
                    telegram_channel = self.url
                elif 't.me/' in self.url:
                    channel_part = self.url.split('t.me/')[-1].split('/')[0]
                    telegram_channel = f"@{channel_part}" if not channel_part.startswith('@') else channel_part

            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑ URL, –∏—â–µ–º –≤ –ë–î
            if not telegram_channel:
                try:
                    with get_db_session() as db:
                        link = db.query(ApiLink).filter(
                            ApiLink.url == self.url
                        ).first()

                        if link and link.telegram_channel:
                            telegram_channel = link.telegram_channel
                            keywords = link.get_telegram_keywords()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î: {e}")

            if not telegram_channel:
                logger.warning("‚ö†Ô∏è Telegram –∫–∞–Ω–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω. –£–∫–∞–∂–∏—Ç–µ –∫–∞–Ω–∞–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ @channelname –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –≤ –ë–î")
                return []

            logger.info(f"üëæ –ö–∞–Ω–∞–ª: {telegram_channel}")
            logger.info(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords if keywords else '–ù–µ—Ç (–±—É–¥—É—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è)'}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –∏–∑ –ë–î –î–û —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Ç–æ–∫–∞
            # –≠—Ç–æ –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å "database is locked" –≤ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–π —Å—Ä–µ–¥–µ
            telegram_api_id = None
            telegram_api_hash = None
            # –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
            # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ —Å TelegramMonitor, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é —Å–µ—Å—Å–∏—é
            telegram_session_file = 'telegram_parser_manual_check'

            try:
                with get_db_session() as db:
                    from data.models import TelegramSettings
                    settings = db.query(TelegramSettings).first()
                    if settings and settings.is_configured:
                        telegram_api_id = settings.api_id
                        telegram_api_hash = settings.api_hash
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ä—É—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
                        logger.info("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ë–î")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ë–î: {e}")

            if not telegram_api_id or not telegram_api_hash:
                logger.error("‚ùå Telegram API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API_ID –∏ API_HASH")
                return []

            # –ö–æ–ø–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å–µ—Å—Å–∏—é –≤ —Ñ–∞–π–ª –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            import os
            import shutil
            main_session = 'sessions/telegram_parser_session.session'
            manual_session = f'sessions/{telegram_session_file}.session'

            if os.path.exists(main_session) and not os.path.exists(manual_session):
                try:
                    shutil.copy2(main_session, manual_session)
                    logger.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ —Å–µ—Å—Å–∏—è –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Å—Å–∏—é: {e}")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
            async def fetch_telegram_messages():
                # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –≤–Ω—É—Ç—Ä–∏ async —Ñ—É–Ω–∫—Ü–∏–∏ —Å —è–≤–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                # –≠—Ç–æ –∏–∑–±–µ–≥–∞–µ—Ç –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–î –∏–∑ –¥—Ä—É–≥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                parser = TelegramParser(
                    api_id=telegram_api_id,
                    api_hash=telegram_api_hash
                )

                try:
                    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è
                    connected = await parser.connect_with_retry(max_retries=2, retry_delay=3)
                    if not connected:
                        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Telegram")
                        return []

                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π
                    logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20 —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {telegram_channel}...")
                    messages = await parser.get_recent_messages(telegram_channel, limit=20)

                    if not messages:
                        logger.info(f"‚ÑπÔ∏è –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–∞–Ω–∞–ª–µ {telegram_channel}")
                        return []

                    logger.info(f"üì¨ –ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
                    promotions = []
                    for msg in messages:
                        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —Ñ–∏–ª—å—Ç—Ä—É–µ–º
                        if keywords:
                            result = await parser.process_message(msg['text'], keywords)
                            if not result:
                                continue
                        else:
                            result = {
                                'matched_keywords': [],
                                'links': parser.extract_links(msg['text']),
                                'dates': parser.extract_dates(msg['text'])
                            }

                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–æ–∞–∫—Ü–∏—é
                        promo = {
                            'promo_id': f"telegram_{telegram_channel.replace('@', '')}_{msg['id']}",
                            'exchange': telegram_channel,
                            'title': f"Telegram: {telegram_channel}",
                            'description': msg['text'][:500],
                            'link': result['links'][0] if result['links'] else f"https://t.me/{telegram_channel.replace('@', '')}/{msg['id']}",
                            'start_time': msg['date'],
                            'total_prize_pool': ', '.join(result['matched_keywords']) if result['matched_keywords'] else None,
                            'data_source': 'telegram',
                            'source_url': self.url
                        }

                        promotions.append(promo)

                    return promotions

                finally:
                    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ
                    await parser.disconnect()

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
            # –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ —Å –æ—Å–Ω–æ–≤–Ω—ã–º event loop
            import threading

            result = [None]  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            exception = [None]  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è

            def run_in_new_loop():
                """–ó–∞–ø—É—Å–∫–∞–µ—Ç async —Ñ—É–Ω–∫—Ü–∏—é –≤ –Ω–æ–≤–æ–º event loop –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
                try:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event loop –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        result[0] = new_loop.run_until_complete(fetch_telegram_messages())
                    finally:
                        new_loop.close()
                except Exception as e:
                    exception[0] = e
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)

            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ...")
            thread = threading.Thread(target=run_in_new_loop, name='telegram_parser_thread')
            thread.start()
            thread.join(timeout=60)  # –ñ–¥–µ–º –º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if thread.is_alive():
                logger.error("‚ùå Timeout: Telegram –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ 60 —Å–µ–∫—É–Ω–¥")
                return []

            if exception[0]:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞: {exception[0]}")
                return []

            promotions = result[0] or []

            logger.info(f"üìä Telegram –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(promotions)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            return promotions

        except ImportError as e:
            logger.error(f"‚ùå TelegramParser –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
            logger.error(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ parsers/telegram_parser.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Telegram –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return []

    def _parse_via_html(self) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ–¥–∏–Ω–æ—á–Ω—ã–º URL"""
        try:
            all_html_urls = []

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π URL –µ—Å–ª–∏ –æ–Ω –Ω–µ API
            if not self._is_api_url():
                all_html_urls.append(self.url)
                logger.info(f"üåê –î–æ–±–∞–≤–ª–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π HTML URL: {self.url}")

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π HTML URL –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ù–û–í–û–ï: –æ–¥–∏–Ω–æ—á–Ω—ã–π)
            if self.html_url and self.html_url not in all_html_urls:
                all_html_urls.append(self.html_url)
                logger.info(f"üåê –î–æ–±–∞–≤–ª–µ–Ω –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π HTML URL –∏–∑ –ë–î: {self.html_url}")

            # –ï—Å–ª–∏ –Ω–µ—Ç URL –∏–∑ –ë–î, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ —à–∞–±–ª–æ–Ω–æ–≤
            if not all_html_urls:
                logger.info(f"üîç –ü–æ–∏—Å–∫ HTML URL –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange} –≤ —à–∞–±–ª–æ–Ω–∞—Ö...")
                html_urls = get_html_urls(self.exchange)

                if not html_urls:
                    logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö HTML URL –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange}")
                    logger.warning(f"   –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å HTML —Å—Å—ã–ª–∫–∏ —á–µ—Ä–µ–∑ –±–æ—Ç –∏–ª–∏ –≤ html_templates.py")
                    return []

                all_html_urls.extend(html_urls)

            logger.info(f"üìã –í—Å–µ–≥–æ {len(all_html_urls)} HTML URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞:")
            for i, url in enumerate(all_html_urls, 1):
                logger.info(f"   {i}. {url}")

            all_html_promos = []

            for i, html_url in enumerate(all_html_urls, 1):
                try:
                    logger.info(f"üåê [{i}/{len(all_html_urls)}] –ü–∞—Ä—Å–∏–Ω–≥ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {html_url}")
                    response = self._make_request(html_url)

                    if not response:
                        logger.warning(f"‚ö†Ô∏è –ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç {html_url}")
                        continue

                    if response.status_code != 200:
                        logger.warning(f"‚ö†Ô∏è –ù–µ—É—Å–ø–µ—à–Ω—ã–π —Å—Ç–∞—Ç—É—Å –∫–æ–¥ {response.status_code} –¥–ª—è {html_url}")
                        continue

                    logger.info(f"‚úÖ HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")

                    html_promos = self._parse_html_content(response.text, html_url)
                    all_html_promos.extend(html_promos)

                    if html_promos:
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(html_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –≤ {html_url}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {html_url}")

                    if i < len(all_html_urls):
                        logger.debug(f"‚è≥ –ü–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º...")
                        time.sleep(2)

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML {html_url}: {e}", exc_info=True)
                    continue

            logger.info(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(all_html_promos)} –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π –∏–∑ –≤—Å–µ—Ö HTML URLs")
            return all_html_promos

        except Exception as e:
            logger.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return []
    
    def _parse_html_content(self, html_content: str, source_url: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            selectors = get_html_selectors(self.exchange)
            
            if not selectors:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –±–∏—Ä–∂–∏ {self.exchange}")
                return []
            
            containers = soup.select(selectors['container'])
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–∞ {self.exchange}")
            
            promotions = []
            
            for container in containers:
                try:
                    promo = self._extract_promo_from_container(container, selectors, source_url)
                    if promo and self._is_valid_promo(promo):
                        promotions.append(promo)
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–º–æ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
                    continue
            
            return promotions
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return []
    
    def _extract_promo_from_container(self, container, selectors: dict, source_url: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –∏–∑ HTML –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        try:
            promo = {
                'exchange': self.exchange,
                'data_source': 'html',
                'source_url': source_url
            }

            title_element = container.select_one(selectors['title'])
            if title_element:
                promo['title'] = title_element.get_text(strip=True)

            desc_element = container.select_one(selectors.get('description', ''))
            if desc_element:
                promo['description'] = desc_element.get_text(strip=True)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏
            link_selector = selectors.get('link', '')
            if link_selector == 'self':
                # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–∞–º —è–≤–ª—è–µ—Ç—Å—è —Å—Å—ã–ª–∫–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, <a> —Ç–µ–≥)
                if container.name == 'a' and container.get('href'):
                    link = container.get('href')
                    if link.startswith('/'):
                        base_domain = '/'.join(source_url.split('/')[:3])
                        promo['link'] = base_domain + link
                    else:
                        promo['link'] = link
            else:
                link_element = container.select_one(link_selector)
                if link_element and link_element.get('href'):
                    link = link_element.get('href')
                    if link.startswith('/'):
                        base_domain = '/'.join(source_url.split('/')[:3])
                        promo['link'] = base_domain + link
                    else:
                        promo['link'] = link
            
            time_element = container.select_one(selectors.get('time', ''))
            if time_element:
                promo['start_time'] = time_element.get_text(strip=True)
            
            prize_element = container.select_one(selectors.get('prize', ''))
            if prize_element:
                promo['total_prize_pool'] = prize_element.get_text(strip=True)
            
            token_element = container.select_one(selectors.get('token', ''))
            if token_element:
                promo['award_token'] = token_element.get_text(strip=True)
            
            participants_element = container.select_one(selectors.get('participants', ''))
            if participants_element:
                promo['participants_count'] = participants_element.get_text(strip=True)
            
            image_element = container.select_one(selectors.get('image', ''))
            if image_element and image_element.get('src'):
                promo['icon'] = image_element.get('src')
            
            if promo.get('title') or promo.get('link'):
                promo['promo_id'] = self._generate_html_promo_id(promo)
                return promo
            
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–º–æ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
            return None
    
    def _generate_html_promo_id(self, promo: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è HTML –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏"""
        try:
            title = promo.get('title', '')
            link = promo.get('link', '')
            exchange = promo.get('exchange', '')
            
            stable_key = f"{exchange}_{title}_{link}"
            content_hash = hashlib.md5(stable_key.encode('utf-8')).hexdigest()[:12]
            return f"{exchange}_html_{content_hash}"
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HTML ID: {e}")
            return f"{self.exchange}_html_error"
    
    def _is_valid_promo(self, promo: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏"""
        if not promo.get('title') and not promo.get('description'):
            return False
        
        if not promo.get('promo_id'):
            return False
        
        return True
    
    def _combine_and_deduplicate(self, promotions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –ø—Ä–æ–º–æ–∞–∫—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            unique_promos = {}
            
            for promo in promotions:
                promo_id = promo.get('promo_id')
                if not promo_id:
                    continue
                
                if promo_id in unique_promos:
                    existing_promo = unique_promos[promo_id]
                    self._merge_promo_data(existing_promo, promo)
                else:
                    unique_promos[promo_id] = promo
            
            return list(unique_promos.values())
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return promotions
    
    def _merge_promo_data(self, existing_promo: Dict[str, Any], new_promo: Dict[str, Any]):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        try:
            for key, value in new_promo.items():
                if key not in existing_promo or not existing_promo[key]:
                    existing_promo[key] = value
            
            if 'data_sources' not in existing_promo:
                existing_promo['data_sources'] = []
            
            source = new_promo.get('data_source', 'unknown')
            if source not in existing_promo['data_sources']:
                existing_promo['data_sources'].append(source)
            
            if len(existing_promo['data_sources']) > 1:
                existing_promo['data_source'] = 'combined'
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def get_strategy_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        return {
            'exchange': self.exchange,
            'strategy_used': self.strategy_used,
            'url': self.url,
            'combined_data_count': len(self.combined_data)
        }

    def get_error_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        # –ü–æ–∫–∞ —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ –æ—à–∏–±–æ–∫
        return {
            'total_errors': 0,
            'api_errors': 0,
            'html_errors': 0
        }


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
if __name__ == "__main__":
    def test_fallback_parser():
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ fallback –ø–∞—Ä—Å–µ—Ä–∞"""
        test_urls = [
            "https://www.mexc.com/api/financialactivity/launchpad/list",  # API
            "https://www.bybit.com/en/trade/spot/token-splash",  # HTML
            "https://www.binance.com/ru/"  # HTML
        ]
        
        for url in test_urls:
            print(f"\n=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {url} ===")
            try:
                parser = UniversalFallbackParser(url)
                promos = parser.get_promotions()
                print(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–º–æ–∞–∫—Ü–∏–π: {len(promos)}")
                if promos:
                    for promo in promos[:2]:
                        print(f" - {promo.get('title')} | {promo.get('link')}")
                print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è: {parser.get_strategy_info()}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    test_fallback_parser()