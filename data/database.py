# data/database.py
from sqlalchemy import create_engine, Index, text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import StaticPool
from contextlib import contextmanager
from datetime import datetime, timedelta
import logging
import threading

Base = declarative_base()

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Base
from data.models import *

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –ë–î
_engine = None
_SessionFactory = None
_lock = threading.RLock()

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î —Å connection pooling"""
    global _engine, _SessionFactory
    
    with _lock:
        if _engine is not None:
            return
            
        database_url = 'sqlite:///data/database.db'
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è SQLite
        engine_kwargs = {
            'echo': False,
            'connect_args': {'check_same_thread': False}
        }
        
        engine_kwargs.update({
            'poolclass': StaticPool,
            'pool_pre_ping': True
        })
        
        _engine = create_engine(database_url, **engine_kwargs)
        _SessionFactory = sessionmaker(bind=_engine)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        create_tables()
        initialize_default_settings()
        
        logging.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

@contextmanager
def get_db_session():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–µ—Å—Å–∏–π –ë–î"""
    session = None
    try:
        if _SessionFactory is None:
            init_database()
            
        session = _SessionFactory()
        yield session
        session.commit()
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ë–î: {e}")
        if session:
            session.rollback()
        raise
            
    finally:
        if session:
            session.close()

def get_db():
    """–£—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    logging.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∏–π get_db(), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_db_session()")
    return _SessionFactory() if _SessionFactory else None

# –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
def create_indexes():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    indexes = [
        Index('idx_proxy_status_speed', ProxyServer.status, ProxyServer.speed_ms),
        Index('idx_proxy_priority', ProxyServer.priority),
        Index('idx_ua_status_success', UserAgent.status, UserAgent.success_rate),
        Index('idx_stats_exchange_time', RotationStats.exchange, RotationStats.timestamp),
        Index('idx_stats_proxy_ua', RotationStats.proxy_id, RotationStats.user_agent_id),
        Index('idx_aggregated_date_exchange', AggregatedStats.date, AggregatedStats.exchange)
    ]
    return indexes

# –¢–†–ê–ù–ó–ê–ö–¶–ò–û–ù–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò
@contextmanager
def transaction_session():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å retry –ª–æ–≥–∏–∫–æ–π"""
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        with get_db_session() as session:
            try:
                yield session
                return
                
            except Exception as e:
                retry_count += 1
                logging.warning(f"‚ö†Ô∏è –ü–æ–≤—Ç–æ—Ä —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ {retry_count}/{max_retries}: {e}")
                
                if retry_count == max_retries:
                    logging.error(f"‚ùå –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    raise

def atomic_operation(operation_func, *args, **kwargs):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry"""
    with transaction_session() as session:
        return operation_func(session, *args, **kwargs)

# –°–ò–°–¢–ï–ú–ê –ú–ò–ì–†–ê–¶–ò–ô
class DatabaseMigration:
    def __init__(self):
        self.migrations = []
        self._register_migrations()
    
    def _register_migrations(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        self.migrations.extend([
            self._migration_001_initial,
            self._migration_002_add_indexes,
            self._migration_003_add_multiple_urls
        ])
    
    def _migration_001_initial(self, session):
        """–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è"""
        pass
    
    def _migration_002_add_indexes(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤"""
        pass

    def _migration_003_add_multiple_urls(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª–µ–π api_urls –∏ html_urls"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]

            # –î–æ–±–∞–≤–ª—è–µ–º api_urls –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if 'api_urls' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN api_urls TEXT DEFAULT '[]'"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü api_urls")

            # –î–æ–±–∞–≤–ª—è–µ–º html_urls –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if 'html_urls' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN html_urls TEXT DEFAULT '[]'"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü html_urls")

            session.commit()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 003: {e}")
            raise
    
    def run_migrations(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        logging.info("üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        with get_db_session() as session:
            for i, migration in enumerate(self.migrations, 1):
                try:
                    migration(session)
                    logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è {i}/{len(self.migrations)} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ {i}: {e}")
                    raise

# –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò
def create_tables():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        Base.metadata.create_all(_engine)
        logging.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
        raise

def initialize_default_settings():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    def _init_settings(session):
        if not session.query(RotationSettings).first():
            default_settings = RotationSettings()
            session.add(default_settings)
            logging.info("‚úÖ –°–æ–∑–¥–∞–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–æ—Ç–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    atomic_operation(_init_settings)

def cleanup_old_data():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    def _cleanup(session):
        settings = session.query(RotationSettings).first()
        if not settings:
            return
            
        # –û—á–∏—Å—Ç–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        cutoff_date = datetime.utcnow() - timedelta(days=settings.stats_retention_days)
        deleted_stats = session.query(RotationStats).filter(
            RotationStats.timestamp < cutoff_date
        ).delete()
        
        # –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
        archive_cutoff = datetime.utcnow() - timedelta(days=settings.archive_inactive_days)
        
        archived_proxies = session.query(ProxyServer).filter(
            ProxyServer.status == 'inactive',
            ProxyServer.last_used < archive_cutoff,
            ProxyServer.archived_at.is_(None)
        ).update({
            'status': 'archived',
            'archived_at': datetime.utcnow()
        })
        
        archived_ua = session.query(UserAgent).filter(
            UserAgent.status == 'inactive', 
            UserAgent.last_used < archive_cutoff,
            UserAgent.archived_at.is_(None)
        ).update({
            'status': 'archived',
            'archived_at': datetime.utcnow()
        })
        
        settings.last_cleanup = datetime.utcnow()
        
        logging.info(f"üóëÔ∏è –û—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–µ–Ω–æ {deleted_stats} –∑–∞–ø–∏—Å–µ–π, "
                    f"–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {archived_proxies} –ø—Ä–æ–∫—Å–∏ –∏ {archived_ua} UA")
    
    atomic_operation(_cleanup)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
init_database()
migration_runner = DatabaseMigration()
migration_runner.run_migrations()