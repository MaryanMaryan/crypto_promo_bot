# data/database.py
from __future__ import annotations
from sqlalchemy import create_engine, Index, text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session, joinedload
from sqlalchemy.pool import StaticPool
from contextlib import contextmanager
from datetime import datetime, timedelta
import logging
import threading

Base = declarative_base()

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Base
from data.models import *

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –ë–î
_engine = None
_SessionFactory = None
_lock = threading.RLock()

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î —Å connection pooling"""
    global _engine, _SessionFactory
    
    with _lock:
        if _engine is not None:
            return
            
        database_url = 'sqlite:///data/database.db'
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è SQLite
        engine_kwargs = {
            'echo': False,
            'connect_args': {
                'check_same_thread': False,
                'timeout': 60.0,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º timeout –¥–æ 60 —Å–µ–∫—É–Ω–¥
                'isolation_level': None  # Autocommit mode –¥–ª—è –ª—É—á—à–µ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            }
        }
        
        engine_kwargs.update({
            'poolclass': StaticPool,
            'pool_pre_ping': True
        })
        
        _engine = create_engine(database_url, **engine_kwargs)
        _SessionFactory = sessionmaker(bind=_engine)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        create_tables()
        initialize_default_settings()
        
        # –í–∫–ª—é—á–∞–µ–º WAL —Ä–µ–∂–∏–º –¥–ª—è –ª—É—á—à–µ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        try:
            with _engine.connect() as conn:
                conn.execute(text('PRAGMA journal_mode=WAL'))
                conn.execute(text('PRAGMA busy_timeout=60000'))  # 60 —Å–µ–∫—É–Ω–¥
                conn.commit()
            logging.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (WAL —Ä–µ–∂–∏–º –≤–∫–ª—é—á–µ–Ω)")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å WAL —Ä–µ–∂–∏–º: {e}")
            logging.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

@contextmanager
def get_db_session():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–µ—Å—Å–∏–π –ë–î"""
    session = None
    try:
        if _SessionFactory is None:
            init_database()
            
        session = _SessionFactory()
        yield session
        session.commit()
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ë–î: {e}")
        if session:
            session.rollback()
        raise
            
    finally:
        if session:
            session.close()

def get_db():
    """–£—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    logging.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∏–π get_db(), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_db_session()")
    return _SessionFactory() if _SessionFactory else None

# –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
def create_indexes():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    indexes = [
        Index('idx_proxy_status_speed', ProxyServer.status, ProxyServer.speed_ms),
        Index('idx_proxy_priority', ProxyServer.priority),
        Index('idx_ua_status_success', UserAgent.status, UserAgent.success_rate),
        Index('idx_stats_exchange_time', RotationStats.exchange, RotationStats.timestamp),
        Index('idx_stats_proxy_ua', RotationStats.proxy_id, RotationStats.user_agent_id),
        Index('idx_aggregated_date_exchange', AggregatedStats.date, AggregatedStats.exchange),
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è Telegram
        Index('idx_tg_channel_username', TelegramChannel.channel_username),
        Index('idx_tg_channel_active', TelegramChannel.is_active),
        Index('idx_tg_message_channel_date', TelegramMessage.channel_id, TelegramMessage.message_date),
        Index('idx_tg_message_notification', TelegramMessage.notification_sent)
    ]
    return indexes

# –¢–†–ê–ù–ó–ê–ö–¶–ò–û–ù–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò
@contextmanager
def transaction_session():
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å retry –ª–æ–≥–∏–∫–æ–π"""
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        session = None
        try:
            if _SessionFactory is None:
                init_database()
            
            session = _SessionFactory()
            yield session
            session.commit()
            return
            
        except Exception as e:
            if session:
                session.rollback()  # –í–ê–ñ–ù–û: –¥–µ–ª–∞–µ–º rollback –ø—Ä–∏ –æ—à–∏–±–∫–µ
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—à–∏–±–∫–∞ "database is locked"
            if "database is locked" in str(e).lower() and retry_count < max_retries - 1:
                retry_count += 1
                logging.warning(f"‚ö†Ô∏è –ü–æ–≤—Ç–æ—Ä —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ {retry_count}/{max_retries}: {e}")
                import time
                time.sleep(0.5 * retry_count)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                continue
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –∏–ª–∏ –∫–æ–≥–¥–∞ retry –∏—Å—á–µ—Ä–ø–∞–Ω—ã
                if retry_count > 0:
                    logging.error(f"‚ùå –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞ –ø–æ—Å–ª–µ {retry_count} –ø–æ–ø—ã—Ç–æ–∫")
                raise
                
        finally:
            if session:
                session.close()

def atomic_operation(operation_func, *args, **kwargs):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry"""
    with transaction_session() as session:
        return operation_func(session, *args, **kwargs)

# –°–ò–°–¢–ï–ú–ê –ú–ò–ì–†–ê–¶–ò–ô
class DatabaseMigration:
    def __init__(self):
        self.migrations = []
        self._register_migrations()
    
    def _register_migrations(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        self.migrations.extend([
            self._migration_001_initial,
            self._migration_002_add_indexes,
            self._migration_003_add_multiple_urls,
            self._migration_004_convert_to_single_urls,
            self._migration_005_add_parsing_type,
            self._migration_006_add_staking_fields,
            self._migration_007_add_telegram_tables,
            self._migration_008_add_telegram_accounts,
            self._migration_009_add_staking_snapshots,
            self._migration_010_add_announcement_fields,
            self._migration_011_add_exchange_credentials,
            self._migration_012_add_combined_staking_fields,
            self._migration_013_add_promo_raw_data,
            self._migration_014_add_is_favorite
        ])

    def _migration_010_add_announcement_fields(self, session):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –¥–ª—è —É–º–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞–Ω–æ–Ω—Å–æ–≤ (announcement_*)"""
        try:
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]
            fields_to_add = {
                'announcement_strategy': 'TEXT',
                'announcement_keywords': "TEXT DEFAULT '[]'",
                'announcement_regex': 'TEXT',
                'announcement_css_selector': 'TEXT',
                'announcement_last_snapshot': 'TEXT',
                'announcement_last_check': 'DATETIME'
            }
            added_count = 0
            for field_name, field_type in fields_to_add.items():
                if field_name not in columns:
                    session.execute(text(f"ALTER TABLE api_links ADD COLUMN {field_name} {field_type}"))
                    logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü {field_name}")
                    added_count += 1
            if added_count > 0:
                session.commit()
                logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 010: –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø–æ–ª–µ–π –¥–ª—è –∞–Ω–æ–Ω—Å–æ–≤")
            else:
                logging.info("‚ÑπÔ∏è –í—Å–µ –ø–æ–ª—è –∞–Ω–æ–Ω—Å–æ–≤ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 010: {e}")
            raise
    
    def _migration_011_add_exchange_credentials(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 011: –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã exchange_credentials –¥–ª—è API –∫–ª—é—á–µ–π –±–∏—Ä–∂"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
            result = session.execute(text(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='exchange_credentials'"
            ))
            if result.fetchone() is not None:
                logging.info("‚ÑπÔ∏è –¢–∞–±–ª–∏—Ü–∞ exchange_credentials —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                return
            
            # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É
            session.execute(text("""
                CREATE TABLE exchange_credentials (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name VARCHAR NOT NULL,
                    exchange VARCHAR NOT NULL,
                    api_key VARCHAR NOT NULL,
                    api_secret VARCHAR NOT NULL,
                    passphrase VARCHAR,
                    is_active BOOLEAN DEFAULT 1,
                    is_verified BOOLEAN DEFAULT 0,
                    last_verified DATETIME,
                    last_used DATETIME,
                    requests_count INTEGER DEFAULT 0,
                    success_count INTEGER DEFAULT 0,
                    error_count INTEGER DEFAULT 0,
                    last_error TEXT,
                    added_by INTEGER NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å
            session.execute(text(
                "CREATE INDEX idx_exchange_active ON exchange_credentials(exchange, is_active)"
            ))
            
            session.commit()
            logging.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 011: –°–æ–∑–¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ exchange_credentials")
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 011: {e}")
            raise
    
    def _migration_001_initial(self, session):
        """–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è"""
        pass
    
    def _migration_002_add_indexes(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤"""
        pass

    def _migration_003_add_multiple_urls(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª–µ–π api_urls –∏ html_urls"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]

            # –î–æ–±–∞–≤–ª—è–µ–º api_urls –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if 'api_urls' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN api_urls TEXT DEFAULT '[]'"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü api_urls")

            # –î–æ–±–∞–≤–ª—è–µ–º html_urls –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if 'html_urls' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN html_urls TEXT DEFAULT '[]'"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü html_urls")

            session.commit()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 003: {e}")
            raise

    def _migration_004_convert_to_single_urls(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 004: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö URL –≤ –æ–¥–∏–Ω–æ—á–Ω—ã–µ"""
        import json

        try:
            # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]

            # –®–∞–≥ 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            if 'api_url' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN api_url TEXT"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü api_url")

            if 'html_url' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN html_url TEXT"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü html_url")

            session.commit()

            # –®–∞–≥ 3: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É—è raw SQL
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ SQL
            result = session.execute(text("SELECT id, url, api_urls, html_urls, api_url, html_url, exchange FROM api_links"))
            rows = result.fetchall()
            converted_count = 0

            for row in rows:
                link_id = row[0]
                url = row[1]
                api_urls_json = row[2]
                html_urls_json = row[3]
                current_api_url = row[4]
                current_html_url = row[5]

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —É–∂–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ
                if current_api_url:
                    continue

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º API URLs
                new_api_url = None
                try:
                    api_urls_list = json.loads(api_urls_json) if api_urls_json else []
                    if api_urls_list:
                        new_api_url = api_urls_list[0]
                    elif url:
                        new_api_url = url
                except:
                    if url:
                        new_api_url = url

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML URLs
                new_html_url = None
                try:
                    html_urls_list = json.loads(html_urls_json) if html_urls_json else []
                    if html_urls_list:
                        new_html_url = html_urls_list[0]
                except:
                    pass

                # –û–±–Ω–æ–≤–ª—è–µ–º —á–µ—Ä–µ–∑ SQL
                if new_api_url:
                    session.execute(text(
                        "UPDATE api_links SET api_url = :api_url, html_url = :html_url, exchange = NULL WHERE id = :id"
                    ), {"api_url": new_api_url, "html_url": new_html_url, "id": link_id})
                    converted_count += 1

            session.commit()
            logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 004: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {converted_count} —Å—Å—ã–ª–æ–∫")
            logging.info(f"   - JSON –º–∞—Å—Å–∏–≤—ã ‚Üí –æ–¥–∏–Ω–æ—á–Ω—ã–µ URL")
            logging.info(f"   - –ü–æ–ª–µ exchange –æ—á–∏—â–µ–Ω–æ")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 004: {e}")
            raise

    def _migration_005_add_parsing_type(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 005: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—è parsing_type"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—è parsing_type
            if 'parsing_type' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN parsing_type TEXT DEFAULT 'combined'"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü parsing_type")
                session.commit()
            else:
                logging.info("‚ÑπÔ∏è –°—Ç–æ–ª–±–µ—Ü parsing_type —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 005: {e}")
            raise

    def _migration_006_add_staking_fields(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 006: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –¥–ª—è —Å—Ç–µ–π–∫–∏–Ω–≥–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π –¥–ª—è —Å—Ç–µ–π–∫–∏–Ω–≥–∞
            fields_to_add = {
                'category': "TEXT DEFAULT 'launches'",
                'page_url': "TEXT",
                'min_apr': "REAL",
                'track_fill': "INTEGER DEFAULT 0",
                'statuses_filter': "TEXT",
                'types_filter': "TEXT"
            }

            added_count = 0
            for field_name, field_type in fields_to_add.items():
                if field_name not in columns:
                    session.execute(text(f"ALTER TABLE api_links ADD COLUMN {field_name} {field_type}"))
                    logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü {field_name}")
                    added_count += 1

            if added_count > 0:
                session.commit()
                logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 006: –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø–æ–ª–µ–π –¥–ª—è —Å—Ç–µ–π–∫–∏–Ω–≥–∞")
            else:
                logging.info("‚ÑπÔ∏è –í—Å–µ –ø–æ–ª—è —Å—Ç–µ–π–∫–∏–Ω–≥–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 006: {e}")
            raise

    def _migration_007_add_telegram_tables(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 007: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –¥–ª—è Telegram-–ø–∞—Ä—Å–µ—Ä–∞"""
        try:
            from sqlalchemy import inspect
            inspector = inspect(session.bind)
            tables = inspector.get_table_names()

            if 'telegram_channels' in tables:
                logging.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ telegram_channels —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            else:
                logging.info("üì° –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã telegram_channels...")

            if 'telegram_messages' in tables:
                logging.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ telegram_messages —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            else:
                logging.info("üì° –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã telegram_messages...")

            # –¢–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ Base.metadata.create_all()
            logging.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 007: Telegram —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã/—Å–æ–∑–¥–∞–Ω—ã")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 007: {e}")
            raise

    def _migration_008_add_telegram_accounts(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 008: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã telegram_accounts –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
        try:
            from sqlalchemy import inspect
            inspector = inspect(session.bind)
            tables = inspector.get_table_names()

            if 'telegram_accounts' in tables:
                logging.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ telegram_accounts —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            else:
                logging.info("üì± –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã telegram_accounts...")
                # –¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ Base.metadata.create_all()

            logging.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 008: –¢–∞–±–ª–∏—Ü–∞ telegram_accounts –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞/—Å–æ–∑–¥–∞–Ω–∞")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 008: {e}")
            raise

    def _migration_009_add_staking_snapshots(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 009: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã staking_snapshots –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        try:
            from sqlalchemy import inspect
            inspector = inspect(session.bind)
            tables = inspector.get_table_names()

            if 'staking_snapshots' in tables:
                logging.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ staking_snapshots —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            else:
                logging.info("üì∏ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã staking_snapshots...")
                # –¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ Base.metadata.create_all()
                from data.models import StakingSnapshot
                StakingSnapshot.__table__.create(session.bind, checkfirst=True)
                logging.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ staking_snapshots —Å–æ–∑–¥–∞–Ω–∞")

            logging.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 009: –¢–∞–±–ª–∏—Ü–∞ staking_snapshots –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞/—Å–æ–∑–¥–∞–Ω–∞")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 009: {e}")
            raise

    def _migration_012_add_combined_staking_fields(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 012: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ Fixed/Flexible (Gate.io)"""
        try:
            result = session.execute(text("PRAGMA table_info(staking_history)"))
            columns = [row[1] for row in result.fetchall()]
            
            fields_to_add = {
                'fixed_apr': 'REAL',
                'fixed_term_days': 'INTEGER',
                'fixed_user_limit': 'REAL',
                'flexible_apr': 'REAL',
                'flexible_user_limit': 'REAL'
            }
            
            added_count = 0
            for field_name, field_type in fields_to_add.items():
                if field_name not in columns:
                    session.execute(text(f"ALTER TABLE staking_history ADD COLUMN {field_name} {field_type}"))
                    logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü {field_name}")
                    added_count += 1
            
            if added_count > 0:
                session.commit()
                logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 012: –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø–æ–ª–µ–π –¥–ª—è Fixed/Flexible –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
            else:
                logging.info("‚ÑπÔ∏è –í—Å–µ –ø–æ–ª—è Fixed/Flexible —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 012: {e}")
            raise

    def _migration_013_add_promo_raw_data(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 013: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π promo_type –∏ raw_data –≤ promo_history –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö API"""
        try:
            result = session.execute(text("PRAGMA table_info(promo_history)"))
            columns = [row[1] for row in result.fetchall()]
            
            fields_to_add = {
                'promo_type': 'TEXT',  # mexc_launchpad, mexc_airdrop, okx_boost, bybit_launchpad –∏ —Ç.–¥.
                'raw_data': 'TEXT'  # JSON —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ API
            }
            
            added_count = 0
            for field_name, field_type in fields_to_add.items():
                if field_name not in columns:
                    session.execute(text(f"ALTER TABLE promo_history ADD COLUMN {field_name} {field_type}"))
                    logging.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü {field_name} –≤ promo_history")
                    added_count += 1
            
            if added_count > 0:
                session.commit()
                logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 013: –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –ø–æ–ª–µ–π –¥–ª—è raw_data")
            else:
                logging.info("‚ÑπÔ∏è –í—Å–µ –ø–æ–ª—è raw_data —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 013: {e}")
            raise

    def _migration_014_add_is_favorite(self, session):
        """–ú–∏–≥—Ä–∞—Ü–∏—è 014: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—è is_favorite –¥–ª—è –∏–∑–±—Ä–∞–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
        try:
            result = session.execute(text("PRAGMA table_info(api_links)"))
            columns = [row[1] for row in result.fetchall()]
            
            if 'is_favorite' not in columns:
                session.execute(text("ALTER TABLE api_links ADD COLUMN is_favorite INTEGER DEFAULT 0"))
                logging.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü is_favorite")
                session.commit()
                logging.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è 014: –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ is_favorite")
            else:
                logging.info("‚ÑπÔ∏è –°—Ç–æ–ª–±–µ—Ü is_favorite —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ 014: {e}")
            raise

    def run_migrations(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        logging.info("üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        with get_db_session() as session:
            for i, migration in enumerate(self.migrations, 1):
                try:
                    migration(session)
                    logging.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è {i}/{len(self.migrations)} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏ {i}: {e}")
                    raise

# –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò
def create_tables():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        Base.metadata.create_all(_engine)
        logging.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {e}")
        raise

def initialize_default_settings():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    def _init_settings(session):
        if not session.query(RotationSettings).first():
            default_settings = RotationSettings()
            session.add(default_settings)
            logging.info("‚úÖ –°–æ–∑–¥–∞–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–æ—Ç–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    atomic_operation(_init_settings)

def cleanup_old_data():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    def _cleanup(session):
        settings = session.query(RotationSettings).first()
        if not settings:
            return
            
        # –û—á–∏—Å—Ç–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        cutoff_date = datetime.utcnow() - timedelta(days=settings.stats_retention_days)
        deleted_stats = session.query(RotationStats).filter(
            RotationStats.timestamp < cutoff_date
        ).delete()
        
        # –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
        archive_cutoff = datetime.utcnow() - timedelta(days=settings.archive_inactive_days)
        
        archived_proxies = session.query(ProxyServer).filter(
            ProxyServer.status == 'inactive',
            ProxyServer.last_used < archive_cutoff,
            ProxyServer.archived_at.is_(None)
        ).update({
            'status': 'archived',
            'archived_at': datetime.utcnow()
        })
        
        archived_ua = session.query(UserAgent).filter(
            UserAgent.status == 'inactive', 
            UserAgent.last_used < archive_cutoff,
            UserAgent.archived_at.is_(None)
        ).update({
            'status': 'archived',
            'archived_at': datetime.utcnow()
        })
        
        settings.last_cleanup = datetime.utcnow()
        
        logging.info(f"üóëÔ∏è –û—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–µ–Ω–æ {deleted_stats} –∑–∞–ø–∏—Å–µ–π, "
                    f"–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {archived_proxies} –ø—Ä–æ–∫—Å–∏ –∏ {archived_ua} UA")
    
    atomic_operation(_cleanup)


# =============================================================================
# ASYNC –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–¢–ó–´–í–ß–ò–í–û–ì–û UI
# =============================================================================

import asyncio
from typing import List, Optional, Any, Callable, TypeVar
from concurrent.futures import ThreadPoolExecutor

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π executor –¥–ª—è async –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ë–î
_db_executor: Optional[ThreadPoolExecutor] = None

def _get_db_executor() -> ThreadPoolExecutor:
    """–ü–æ–ª—É—á–∏—Ç—å executor –¥–ª—è async –ë–î –æ–ø–µ—Ä–∞—Ü–∏–π"""
    global _db_executor
    if _db_executor is None:
        _db_executor = ThreadPoolExecutor(max_workers=5, thread_name_prefix="db_async_")
    return _db_executor


async def run_in_db_executor(func: Callable, *args, **kwargs) -> Any:
    """
    –í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        result = await run_in_db_executor(my_sync_function, arg1, arg2)
    """
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(_get_db_executor(), lambda: func(*args, **kwargs))


async def get_links_async(
    category: Optional[str] = None,
    is_active: Optional[bool] = None
) -> List[ApiLink]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫
    
    Args:
        category: –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ('airdrop', 'staking', etc.)
        is_active: –§–∏–ª—å—Ç—Ä –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    
    Returns:
        –°–ø–∏—Å–æ–∫ ApiLink –æ–±—ä–µ–∫—Ç–æ–≤
    """
    from utils.cache import get_cache_manager, CacheKeys
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á –∫—ç—à–∞
    cache_key = f"links:all:{category or 'all'}:{is_active}"
    cache = get_cache_manager()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cached = cache.get(cache_key)
    if cached is not None:
        return cached
    
    def _get_links():
        with get_db_session() as db:
            query = db.query(ApiLink).options(
                joinedload(ApiLink.telegram_account)  # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–π telegram_account
            )
            
            if category:
                query = query.filter(ApiLink.category == category)
            if is_active is not None:
                query = query.filter(ApiLink.is_active == is_active)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (—É–∂–µ –≤–∫–ª—é—á–∞—è telegram_account —á–µ—Ä–µ–∑ joinedload)
            links = query.all()
            
            # –î–µ—Ç–∞—á–∏–º –æ–±—ä–µ–∫—Ç—ã –æ—Ç —Å–µ—Å—Å–∏–∏
            for link in links:
                # –¢–∞–∫–∂–µ –¥–µ—Ç–∞—á–∏–º telegram_account –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω
                if link.telegram_account:
                    db.expunge(link.telegram_account)
                db.expunge(link)
            
            return links
    
    links = await run_in_db_executor(_get_links)
    
    # –ö—ç—à–∏—Ä—É–µ–º –Ω–∞ 30 —Å–µ–∫—É–Ω–¥
    cache.set(cache_key, links, ttl=30)
    
    return links


async def get_link_by_id_async(link_id: int) -> Optional[ApiLink]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –ø–æ ID
    
    Args:
        link_id: ID —Å—Å—ã–ª–∫–∏
    
    Returns:
        ApiLink –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
    """
    from utils.cache import get_cache_manager, CacheKeys
    
    cache_key = CacheKeys.link_by_id(link_id)
    cache = get_cache_manager()
    
    cached = cache.get(cache_key)
    if cached is not None:
        return cached
    
    def _get_link():
        with get_db_session() as db:
            link = db.query(ApiLink).filter(ApiLink.id == link_id).first()
            if link:
                db.expunge(link)
            return link
    
    link = await run_in_db_executor(_get_link)
    
    if link:
        cache.set(cache_key, link, ttl=30)
    
    return link


async def get_active_links_count_async() -> int:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
    from utils.cache import get_cache_manager
    
    cache = get_cache_manager()
    cache_key = "links:active_count"
    
    cached = cache.get(cache_key)
    if cached is not None:
        return cached
    
    def _count():
        with get_db_session() as db:
            return db.query(ApiLink).filter(ApiLink.is_active == True).count()
    
    count = await run_in_db_executor(_count)
    cache.set(cache_key, count, ttl=30)
    
    return count


async def get_links_by_category_async(category: str) -> List[ApiLink]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    
    Args:
        category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è ('airdrop', 'staking', 'launchpool', 'announcement')
    """
    return await get_links_async(category=category)


async def get_favorite_links_async() -> List[ApiLink]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑–±—Ä–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏
    
    Returns:
        –°–ø–∏—Å–æ–∫ ApiLink –æ–±—ä–µ–∫—Ç–æ–≤ —Å is_favorite=True
    """
    from utils.cache import get_cache_manager
    
    cache_key = "links:favorites"
    cache = get_cache_manager()
    
    cached = cache.get(cache_key)
    if cached is not None:
        return cached
    
    def _get_favorites():
        with get_db_session() as db:
            query = db.query(ApiLink).options(
                joinedload(ApiLink.telegram_account)
            ).filter(ApiLink.is_favorite == True)
            
            links = query.all()
            
            for link in links:
                if link.telegram_account:
                    db.expunge(link.telegram_account)
                db.expunge(link)
            
            return links
    
    links = await run_in_db_executor(_get_favorites)
    cache.set(cache_key, links, ttl=30)
    
    return links


async def update_link_async(link_id: int, **updates) -> bool:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—è —Å—Å—ã–ª–∫–∏
    
    Args:
        link_id: ID —Å—Å—ã–ª–∫–∏
        **updates: –ü–æ–ª—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, is_active=False)
    
    Returns:
        True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
    """
    from utils.cache import invalidate_links_cache
    
    def _update():
        with get_db_session() as db:
            link = db.query(ApiLink).filter(ApiLink.id == link_id).first()
            if not link:
                return False
            
            for key, value in updates.items():
                if hasattr(link, key):
                    setattr(link, key, value)
            
            return True
    
    result = await run_in_db_executor(_update)
    
    # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à
    if result:
        invalidate_links_cache()
    
    return result


async def delete_link_async(link_id: int) -> bool:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —É–¥–∞–ª–∏—Ç—å —Å—Å—ã–ª–∫—É
    
    Args:
        link_id: ID —Å—Å—ã–ª–∫–∏
    
    Returns:
        True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
    """
    from utils.cache import invalidate_links_cache
    
    def _delete():
        with get_db_session() as db:
            link = db.query(ApiLink).filter(ApiLink.id == link_id).first()
            if not link:
                return False
            
            db.delete(link)
            return True
    
    result = await run_in_db_executor(_delete)
    
    if result:
        invalidate_links_cache()
    
    return result


async def create_link_async(**link_data) -> Optional[ApiLink]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —Å—Å—ã–ª–∫—É
    
    Args:
        **link_data: –ü–æ–ª—è –¥–ª—è –Ω–æ–≤–æ–π —Å—Å—ã–ª–∫–∏
    
    Returns:
        –°–æ–∑–¥–∞–Ω–Ω—ã–π ApiLink –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
    """
    from utils.cache import invalidate_links_cache
    
    def _create():
        with get_db_session() as db:
            link = ApiLink(**link_data)
            db.add(link)
            db.flush()
            db.refresh(link)
            db.expunge(link)
            return link
    
    link = await run_in_db_executor(_create)
    
    if link:
        invalidate_links_cache()
    
    return link


# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
init_database()
migration_runner = DatabaseMigration()
migration_runner.run_migrations()